{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eae352c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Built wheel for scikit-surprise is invalid: Wheel has unexpected file name: expected 'scikit-surprise', got 'unknown'\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (scikit-surprise)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q sentence-transformers scikit-learn scikit-surprise ortools tqdm pandas numpy joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc428147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: c:\\Users\\jaiad\\miniconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - scikit-surprise\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    joblib-1.5.2               |     pyhd8ed1ab_0         219 KB  conda-forge\n",
      "    libblas-3.9.0              |  35_h5709861_mkl          64 KB  conda-forge\n",
      "    libcblas-3.9.0             |  35_h2a3cdd5_mkl          65 KB  conda-forge\n",
      "    libhwloc-2.11.2            |default_ha69328c_1001         2.3 MB  conda-forge\n",
      "    liblapack-3.9.0            |  35_hf9ab0e9_mkl          77 KB  conda-forge\n",
      "    libwinpthread-12.0.0.r4.gg4f2fc60ca|      h57928b3_10          36 KB  conda-forge\n",
      "    llvm-openmp-21.1.5         |       hfa2b4ca_0         340 KB  conda-forge\n",
      "    mkl-2024.2.2               |      h57928b3_16        98.3 MB  conda-forge\n",
      "    numpy-1.26.4               |  py312h8753938_0         6.2 MB  conda-forge\n",
      "    scikit-surprise-1.1.4      |  py312h0829862_1         535 KB  conda-forge\n",
      "    scipy-1.16.3               |  py312h33376e8_0        14.4 MB  conda-forge\n",
      "    tbb-2021.13.0              |       h62715c5_1         148 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       122.7 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  joblib             conda-forge/noarch::joblib-1.5.2-pyhd8ed1ab_0 \n",
      "  libblas            conda-forge/win-64::libblas-3.9.0-35_h5709861_mkl \n",
      "  libcblas           conda-forge/win-64::libcblas-3.9.0-35_h2a3cdd5_mkl \n",
      "  libhwloc           conda-forge/win-64::libhwloc-2.11.2-default_ha69328c_1001 \n",
      "  liblapack          conda-forge/win-64::liblapack-3.9.0-35_hf9ab0e9_mkl \n",
      "  libwinpthread      conda-forge/win-64::libwinpthread-12.0.0.r4.gg4f2fc60ca-h57928b3_10 \n",
      "  llvm-openmp        conda-forge/win-64::llvm-openmp-21.1.5-hfa2b4ca_0 \n",
      "  mkl                conda-forge/win-64::mkl-2024.2.2-h57928b3_16 \n",
      "  numpy              conda-forge/win-64::numpy-1.26.4-py312h8753938_0 \n",
      "  scikit-surprise    conda-forge/win-64::scikit-surprise-1.1.4-py312h0829862_1 \n",
      "  scipy              conda-forge/win-64::scipy-1.16.3-py312h33376e8_0 \n",
      "  tbb                conda-forge/win-64::tbb-2021.13.0-h62715c5_1 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages: ...working...\n",
      "mkl-2024.2.2         | 98.3 MB   |            |   0% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   |            |   0% \u001b[A\n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    |            |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libhwloc-2.11.2      | 2.3 MB    |            |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "scikit-surprise-1.1. | 535 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "llvm-openmp-21.1.5   | 340 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "joblib-1.5.2         | 219 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tbb-2021.13.0        | 148 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "liblapack-3.9.0      | 77 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libcblas-3.9.0       | 65 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libblas-3.9.0        | 64 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libwinpthread-12.0.0 | 36 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    |            |   0% \u001b[A\u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   |            |   0% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   |            |   0% \u001b[A\n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    | 5          |   6% \u001b[A\u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   |            |   0% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | 2          |   2% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libhwloc-2.11.2      | 2.3 MB    |            |   1% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    | #          |  10% \u001b[A\u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   |            |   1% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | 4          |   4% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libhwloc-2.11.2      | 2.3 MB    | #1         |  12% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    | #4         |  14% \u001b[A\u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   |            |   1% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | 5          |   6% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libhwloc-2.11.2      | 2.3 MB    | ##2        |  23% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    | #8         |  18% \u001b[A\u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 1          |   1% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | 7          |   8% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libhwloc-2.11.2      | 2.3 MB    | ###3       |  34% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    | ##2        |  22% \u001b[A\u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 1          |   1% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | 9          |  10% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libhwloc-2.11.2      | 2.3 MB    | ####3      |  43% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    | ##6        |  26% \u001b[A\u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 1          |   2% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | #1         |  11% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libhwloc-2.11.2      | 2.3 MB    | #####5     |  56% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    | ###        |  31% \u001b[A\u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 1          |   2% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | #2         |  13% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libhwloc-2.11.2      | 2.3 MB    | ######5    |  66% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "scikit-surprise-1.1. | 535 KB    | 2          |   3% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    | ###4       |  35% \u001b[A\u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 2          |   2% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | #4         |  15% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "scikit-surprise-1.1. | 535 KB    | ###8       |  39% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libhwloc-2.11.2      | 2.3 MB    | #######6   |  76% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    | ###8       |  38% \u001b[A\u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 2          |   2% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | #6         |  16% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "scikit-surprise-1.1. | 535 KB    | ########   |  81% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libhwloc-2.11.2      | 2.3 MB    | ########6  |  86% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "scikit-surprise-1.1. | 535 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    | ####1      |  42% \u001b[A\u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 2          |   3% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | #7         |  18% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libhwloc-2.11.2      | 2.3 MB    | #########5 |  96% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "llvm-openmp-21.1.5   | 340 KB    | 4          |   5% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libhwloc-2.11.2      | 2.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 2          |   3% \n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    | ####5      |  46% \u001b[A\u001b[A\n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | #9         |  20% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "llvm-openmp-21.1.5   | 340 KB    | #######5   |  75% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "joblib-1.5.2         | 219 KB    | 7          |   7% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "llvm-openmp-21.1.5   | 340 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 3          |   3% \n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    | ####9      |  50% \u001b[A\u001b[A\n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | ##1        |  21% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "joblib-1.5.2         | 219 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 3          |   3% \n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    | #####3     |  54% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "liblapack-3.9.0      | 77 KB     | ##         |  21% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | ##2        |  23% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "liblapack-3.9.0      | 77 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tbb-2021.13.0        | 148 KB    | #          |  11% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 3          |   4% \n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    | #####8     |  59% \u001b[A\u001b[A\n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | ##4        |  25% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libcblas-3.9.0       | 65 KB     | ##4        |  25% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tbb-2021.13.0        | 148 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libcblas-3.9.0       | 65 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "scikit-surprise-1.1. | 535 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 3          |   4% \n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    | ######3    |  63% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "llvm-openmp-21.1.5   | 340 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libblas-3.9.0        | 64 KB     | ##4        |  25% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | ##6        |  27% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libwinpthread-12.0.0 | 36 KB     | ####4      |  45% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libwinpthread-12.0.0 | 36 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libblas-3.9.0        | 64 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 4          |   4% \n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    | ######8    |  68% \u001b[A\u001b[A\n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | ##9        |  29% \u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 4          |   5% \n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    | #######3   |  74% \u001b[A\u001b[A\n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | ###1       |  31% \u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 4          |   5% \n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    | #######9   |  79% \u001b[A\u001b[A\n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | ###3       |  34% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "liblapack-3.9.0      | 77 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "liblapack-3.9.0      | 77 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 5          |   5% \n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    | ########4  |  85% \u001b[A\u001b[A\n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | ###6       |  36% \u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 5          |   6% \n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    | #########  |  90% \u001b[A\u001b[A\n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | ###8       |  38% \u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 5          |   6% \n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    | #########5 |  96% \u001b[A\u001b[A\n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | ####       |  41% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tbb-2021.13.0        | 148 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tbb-2021.13.0        | 148 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 6          |   6% \n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | ####3      |  43% \u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 6          |   7% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | ####6      |  47% \u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 7          |   7% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | #####      |  50% \u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 7          |   8% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | #####3     |  53% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "joblib-1.5.2         | 219 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libcblas-3.9.0       | 65 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "joblib-1.5.2         | 219 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libcblas-3.9.0       | 65 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 8          |   8% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | #####6     |  57% \u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 8          |   9% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | ######     |  60% \u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 9          |   9% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | ######3    |  63% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libwinpthread-12.0.0 | 36 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libwinpthread-12.0.0 | 36 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | 9          |  10% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | ######6    |  67% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libblas-3.9.0        | 64 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libblas-3.9.0        | 64 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | #          |  10% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | #######    |  70% \u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | #          |  11% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | #######3   |  74% \u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | #1         |  11% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | #######7   |  77% \u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | #1         |  12% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | ########   |  81% \u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | #2         |  12% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | ########4  |  84% \u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | #2         |  13% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | ########7  |  88% \u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | #3         |  13% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | #########1 |  91% \u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | #3         |  14% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | #########4 |  95% \u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | #4         |  15% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | #########8 |  98% \u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | #5         |  15% \n",
      "mkl-2024.2.2         | 98.3 MB   | #6         |  16% \n",
      "\n",
      "\n",
      "\n",
      "libhwloc-2.11.2      | 2.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | #7         |  17% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | ########## | 100% \u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | #8         |  18% \n",
      "mkl-2024.2.2         | 98.3 MB   | #9         |  19% \n",
      "mkl-2024.2.2         | 98.3 MB   | ##         |  20% \n",
      "mkl-2024.2.2         | 98.3 MB   | ##1        |  21% \n",
      "mkl-2024.2.2         | 98.3 MB   | ##2        |  22% \n",
      "mkl-2024.2.2         | 98.3 MB   | ##3        |  23% \n",
      "mkl-2024.2.2         | 98.3 MB   | ##4        |  24% \n",
      "mkl-2024.2.2         | 98.3 MB   | ##5        |  25% \n",
      "mkl-2024.2.2         | 98.3 MB   | ##6        |  26% \n",
      "mkl-2024.2.2         | 98.3 MB   | ##7        |  27% \n",
      "mkl-2024.2.2         | 98.3 MB   | ##8        |  28% \n",
      "mkl-2024.2.2         | 98.3 MB   | ##9        |  29% \n",
      "mkl-2024.2.2         | 98.3 MB   | ###        |  30% \n",
      "mkl-2024.2.2         | 98.3 MB   | ###1       |  31% \n",
      "mkl-2024.2.2         | 98.3 MB   | ###2       |  32% \n",
      "mkl-2024.2.2         | 98.3 MB   | ###3       |  33% \n",
      "mkl-2024.2.2         | 98.3 MB   | ###4       |  34% \n",
      "mkl-2024.2.2         | 98.3 MB   | ###5       |  35% \n",
      "mkl-2024.2.2         | 98.3 MB   | ###6       |  36% \n",
      "mkl-2024.2.2         | 98.3 MB   | ###7       |  37% \n",
      "mkl-2024.2.2         | 98.3 MB   | ###8       |  38% \n",
      "mkl-2024.2.2         | 98.3 MB   | ###9       |  39% \n",
      "mkl-2024.2.2         | 98.3 MB   | ####       |  40% \n",
      "mkl-2024.2.2         | 98.3 MB   | ####1      |  41% \n",
      "mkl-2024.2.2         | 98.3 MB   | ####2      |  42% \n",
      "mkl-2024.2.2         | 98.3 MB   | ####3      |  43% \n",
      "mkl-2024.2.2         | 98.3 MB   | ####4      |  44% \n",
      "mkl-2024.2.2         | 98.3 MB   | ####5      |  45% \n",
      "mkl-2024.2.2         | 98.3 MB   | ####6      |  46% \n",
      "mkl-2024.2.2         | 98.3 MB   | ####7      |  47% \n",
      "mkl-2024.2.2         | 98.3 MB   | ####8      |  48% \n",
      "mkl-2024.2.2         | 98.3 MB   | ####9      |  49% \n",
      "mkl-2024.2.2         | 98.3 MB   | #####      |  50% \n",
      "mkl-2024.2.2         | 98.3 MB   | #####1     |  51% \n",
      "mkl-2024.2.2         | 98.3 MB   | #####2     |  52% \n",
      "mkl-2024.2.2         | 98.3 MB   | #####3     |  53% \n",
      "mkl-2024.2.2         | 98.3 MB   | #####4     |  54% \n",
      "mkl-2024.2.2         | 98.3 MB   | #####5     |  55% \n",
      "mkl-2024.2.2         | 98.3 MB   | #####6     |  56% \n",
      "mkl-2024.2.2         | 98.3 MB   | #####7     |  57% \n",
      "mkl-2024.2.2         | 98.3 MB   | #####8     |  58% \n",
      "mkl-2024.2.2         | 98.3 MB   | #####9     |  59% \n",
      "mkl-2024.2.2         | 98.3 MB   | ######     |  60% \n",
      "mkl-2024.2.2         | 98.3 MB   | ######1    |  62% \n",
      "mkl-2024.2.2         | 98.3 MB   | ######2    |  63% \n",
      "\n",
      "\n",
      "numpy-1.26.4         | 6.2 MB    | ########## | 100% \u001b[A\u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | ######3    |  64% \n",
      "mkl-2024.2.2         | 98.3 MB   | ######4    |  65% \n",
      "mkl-2024.2.2         | 98.3 MB   | ######5    |  66% \n",
      "mkl-2024.2.2         | 98.3 MB   | ######6    |  67% \n",
      "mkl-2024.2.2         | 98.3 MB   | ######7    |  68% \n",
      "mkl-2024.2.2         | 98.3 MB   | ######8    |  69% \n",
      "mkl-2024.2.2         | 98.3 MB   | ######9    |  70% \n",
      "mkl-2024.2.2         | 98.3 MB   | #######    |  71% \n",
      "mkl-2024.2.2         | 98.3 MB   | #######1   |  72% \n",
      "mkl-2024.2.2         | 98.3 MB   | #######2   |  73% \n",
      "mkl-2024.2.2         | 98.3 MB   | #######3   |  74% \n",
      "mkl-2024.2.2         | 98.3 MB   | #######4   |  75% \n",
      "mkl-2024.2.2         | 98.3 MB   | #######5   |  76% \n",
      "mkl-2024.2.2         | 98.3 MB   | #######6   |  77% \n",
      "mkl-2024.2.2         | 98.3 MB   | #######7   |  78% \n",
      "mkl-2024.2.2         | 98.3 MB   | #######8   |  79% \n",
      "mkl-2024.2.2         | 98.3 MB   | #######9   |  80% \n",
      "mkl-2024.2.2         | 98.3 MB   | ########   |  81% \n",
      "mkl-2024.2.2         | 98.3 MB   | ########1  |  82% \n",
      "\n",
      "scipy-1.16.3         | 14.4 MB   | ########## | 100% \u001b[A\n",
      "mkl-2024.2.2         | 98.3 MB   | ########2  |  83% \n",
      "mkl-2024.2.2         | 98.3 MB   | ########3  |  84% \n",
      "mkl-2024.2.2         | 98.3 MB   | ########4  |  85% \n",
      "mkl-2024.2.2         | 98.3 MB   | ########5  |  86% \n",
      "mkl-2024.2.2         | 98.3 MB   | ########6  |  87% \n",
      "mkl-2024.2.2         | 98.3 MB   | ########7  |  88% \n",
      "mkl-2024.2.2         | 98.3 MB   | ########8  |  89% \n",
      "mkl-2024.2.2         | 98.3 MB   | ########9  |  90% \n",
      "mkl-2024.2.2         | 98.3 MB   | #########  |  91% \n",
      "mkl-2024.2.2         | 98.3 MB   | #########1 |  92% \n",
      "mkl-2024.2.2         | 98.3 MB   | #########2 |  93% \n",
      "mkl-2024.2.2         | 98.3 MB   | #########3 |  94% \n",
      "mkl-2024.2.2         | 98.3 MB   | #########4 |  95% \n",
      "mkl-2024.2.2         | 98.3 MB   | #########5 |  96% \n",
      "mkl-2024.2.2         | 98.3 MB   | #########6 |  97% \n",
      "mkl-2024.2.2         | 98.3 MB   | #########7 |  98% \n",
      "mkl-2024.2.2         | 98.3 MB   | #########8 |  99% \n",
      "mkl-2024.2.2         | 98.3 MB   | #########9 | 100% \n",
      "mkl-2024.2.2         | 98.3 MB   | ########## | 100% \n",
      "mkl-2024.2.2         | 98.3 MB   | ########## | 100% \n",
      "                                                     \n",
      "\n",
      "\n",
      "                                                     \u001b[A\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A done\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge scikit-surprise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e31ebea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Using cached scikit_learn-1.7.2-cp312-cp312-win_amd64.whl (8.7 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.7.2 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97bf22e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ortools\n",
      "  Using cached ortools-9.14.6206-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting absl-py>=2.0.0 (from ortools)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from ortools) (1.26.4)\n",
      "Requirement already satisfied: pandas>=2.0.0 in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from ortools) (2.3.3)\n",
      "Collecting protobuf<6.32,>=6.31.1 (from ortools)\n",
      "  Using cached protobuf-6.31.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from ortools) (4.15.0)\n",
      "Collecting immutabledict>=3.0.0 (from ortools)\n",
      "  Using cached immutabledict-4.2.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from pandas>=2.0.0->ortools) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from pandas>=2.0.0->ortools) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from pandas>=2.0.0->ortools) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->ortools) (1.17.0)\n",
      "Using cached ortools-9.14.6206-cp312-cp312-win_amd64.whl (20.5 MB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached immutabledict-4.2.2-py3-none-any.whl (4.7 kB)\n",
      "Using cached protobuf-6.31.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Installing collected packages: protobuf, immutabledict, absl-py, ortools\n",
      "Successfully installed absl-py-2.3.1 immutabledict-4.2.2 ortools-9.14.6206 protobuf-6.31.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ortools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c66c566d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.9.0-cp312-cp312-win_amd64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from sentence-transformers) (1.16.3)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-1.1.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Using cached pillow-12.0.0-cp312-cp312-win_amd64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Collecting filelock (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Collecting pyyaml>=5.1 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached pyyaml-6.0.3-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting shellingham (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting typer-slim (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached regex-2025.11.3-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.3)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached markupsafe-3.0.3-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.10.5)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting click>=8.0.0 (from typer-slim->huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Using cached sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "Using cached torch-2.9.0-cp312-cp312-win_amd64.whl (109.3 MB)\n",
      "Using cached transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "Using cached pillow-12.0.0-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "Using cached fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Using cached pyyaml-6.0.3-cp312-cp312-win_amd64.whl (154 kB)\n",
      "Using cached regex-2025.11.3-cp312-cp312-win_amd64.whl (277 kB)\n",
      "Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached markupsafe-3.0.3-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, safetensors, regex, pyyaml, Pillow, networkx, MarkupSafe, fsspec, filelock, jinja2, huggingface-hub, torch, tokenizers, transformers, sentence-transformers\n",
      "Successfully installed MarkupSafe-3.0.3 Pillow-12.0.0 filelock-3.20.0 fsspec-2025.10.0 huggingface-hub-0.36.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 pyyaml-6.0.3 regex-2025.11.3 safetensors-0.6.2 sentence-transformers-5.1.2 sympy-1.14.0 tokenizers-0.22.1 torch-2.9.0 transformers-4.57.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d3bacd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost==1.7.6\n",
      "  Downloading xgboost-1.7.6-py3-none-win_amd64.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from xgboost==1.7.6) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\jaiad\\miniconda3\\lib\\site-packages (from xgboost==1.7.6) (1.16.3)\n",
      "Downloading xgboost-1.7.6-py3-none-win_amd64.whl (70.9 MB)\n",
      "   ---------------------------------------- 0.0/70.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 1.0/70.9 MB 10.1 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 2.4/70.9 MB 6.1 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 4.5/70.9 MB 7.5 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 6.6/70.9 MB 8.2 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 8.7/70.9 MB 8.5 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 10.5/70.9 MB 8.8 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 12.8/70.9 MB 9.1 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 14.9/70.9 MB 9.2 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 17.0/70.9 MB 9.3 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 19.1/70.9 MB 9.4 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 21.5/70.9 MB 9.5 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 23.6/70.9 MB 9.6 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 26.0/70.9 MB 9.6 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 28.0/70.9 MB 9.7 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 30.4/70.9 MB 9.7 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 32.2/70.9 MB 9.7 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 34.3/70.9 MB 9.8 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 36.7/70.9 MB 9.8 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 38.8/70.9 MB 9.8 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 41.2/70.9 MB 9.8 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 43.3/70.9 MB 9.9 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 45.4/70.9 MB 9.9 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 47.4/70.9 MB 9.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 49.8/70.9 MB 9.9 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 51.9/70.9 MB 9.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 54.3/70.9 MB 9.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 56.4/70.9 MB 9.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 58.7/70.9 MB 10.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 60.8/70.9 MB 10.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 62.4/70.9 MB 10.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 62.4/70.9 MB 10.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 62.4/70.9 MB 10.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 64.5/70.9 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 66.6/70.9 MB 9.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 68.4/70.9 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  70.8/70.9 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 70.9/70.9 MB 9.0 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "  Attempting uninstall: xgboost\n",
      "    Found existing installation: xgboost 3.1.1\n",
      "    Uninstalling xgboost-3.1.1:\n",
      "      Successfully uninstalled xgboost-3.1.1\n",
      "Successfully installed xgboost-1.7.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\jaiad\\miniconda3\\Lib\\site-packages\\~gboost'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost==1.7.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d083914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 â€” Imports & config\n",
    "import os, time, random, math, warnings, json\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np, pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# NLP embeddings + TF-IDF\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Preprocessing + models\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score, ndcg_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Collaborative filtering\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import GridSearchCV as SurpriseGridSearch\n",
    "\n",
    "# ILP allocation\n",
    "from ortools.linear_solver import pywraplp\n",
    "\n",
    "# utils\n",
    "import joblib\n",
    "\n",
    "# Config\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "USE_SBERT = True\n",
    "TOP_K = 10\n",
    "NUM_STUDENTS = 500\n",
    "NUM_INTERNSHIPS = 140\n",
    "OUT_DIR = \"outputs_recommender_v2\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "BASE_ALPHA, BASE_BETA, BASE_GAMMA = 0.40, 0.40, 0.20\n",
    "FAIRNESS_BOOST = {\"rural\": 0.10, \"female\": 0.08}\n",
    "GLOBAL_RESERVED_PERCENT = 0.10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adda62e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic students: 500  internships: 140\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 â€” Synthetic data generation\n",
    "skills_pool = [\n",
    "    'python','sql','machine learning','deep learning','nlp','computer vision','java','spring','react','nodejs',\n",
    "    'html','css','figma','ux','r','excel','powerbi','tableau','docker','kubernetes','aws','gcp','flask','fastapi',\n",
    "    'graphql','android','ios','matlab','c++','sales','marketing','finance','excel','business analysis'\n",
    "]\n",
    "domains = ['Data Science','Backend Development','Frontend Design','DevOps','Mobile','Product','Marketing','Finance']\n",
    "states_pool = ['Uttar Pradesh','Maharashtra','Karnataka','Tamil Nadu','West Bengal','Telangana','Gujarat','Rajasthan','Kerala','Punjab']\n",
    "\n",
    "def make_student(i):\n",
    "    n_skills = np.random.randint(2,6)\n",
    "    skills = ', '.join(np.random.choice(skills_pool, n_skills, replace=False))\n",
    "    domain = np.random.choice(domains)\n",
    "    age = int(np.random.randint(18, 32))\n",
    "    govt_project = int(random.random() < 0.12)\n",
    "    freelancer = int(random.random() < 0.25)\n",
    "    project_impact = float(np.clip(np.random.beta(2,4), 0, 1))\n",
    "    is_fresher = int(random.random() < 0.7)\n",
    "    github = f\"https://github.com/user_{i}\" if random.random() < 0.55 else \"\"\n",
    "    state = np.random.choice(states_pool)\n",
    "    rural = int(random.random() < 0.28)\n",
    "    female = int(random.random() < 0.46)\n",
    "    return {\n",
    "        'student_id': f\"S{i:05d}\", 'skills': skills, 'domain': domain, 'age': age,\n",
    "        'govt_project': govt_project, 'freelancer': freelancer, 'project_impact': project_impact,\n",
    "        'is_fresher': is_fresher, 'github': github, 'state': state, 'rural': rural, 'female': female\n",
    "    }\n",
    "\n",
    "def make_internship(j):\n",
    "    n_req = np.random.randint(2,5)\n",
    "    req_skills = ', '.join(np.random.choice(skills_pool, n_req, replace=False))\n",
    "    domain = np.random.choice(domains)\n",
    "    min_age = 18\n",
    "    max_age = int(np.random.choice([22,25,28,30,35]))\n",
    "    stipend = int(np.random.choice([5000,8000,10000,15000,20000]))\n",
    "    remote = int(random.random() < 0.35)\n",
    "    capacity = int(np.random.randint(1,6))\n",
    "    org_pref_govt = int(random.random() < 0.08)\n",
    "    ministry = np.random.choice(['MeitY','NITI Aayog','MoE','ICAR','MoHFW','Ministry of Culture'])\n",
    "    state = np.random.choice(states_pool)\n",
    "    csr_underprivileged_pct = float(np.random.choice([0.0, 0.05, 0.1, 0.2]))\n",
    "    title = f\"{domain} Intern\"\n",
    "    description = f\"{req_skills} - Work on {domain} projects; stipend {stipend}\"\n",
    "    return {\n",
    "        'internship_id': f\"I{j:05d}\", 'title': title, 'required_skills': req_skills,\n",
    "        'domain': domain, 'min_age': min_age, 'max_age': max_age, 'stipend': stipend,\n",
    "        'remote': remote, 'capacity': capacity, 'org_pref_govt': org_pref_govt,\n",
    "        'ministry': ministry, 'state': state, 'csr_underprivileged_pct': csr_underprivileged_pct,\n",
    "        'description': description\n",
    "    }\n",
    "\n",
    "students = pd.DataFrame([make_student(i) for i in range(1, NUM_STUDENTS+1)])\n",
    "internships = pd.DataFrame([make_internship(j) for j in range(1, NUM_INTERNSHIPS+1)])\n",
    "students['profile_text'] = students['skills'] + ' ' + students['domain'] + ' project_impact:' + students['project_impact'].astype(str)\n",
    "internships['job_text'] = internships['required_skills'] + ' ' + internships['domain'] + ' stipend:' + internships['stipend'].astype(str)\n",
    "students.to_csv(os.path.join(OUT_DIR, \"students_synthetic.csv\"), index=False)\n",
    "internships.to_csv(os.path.join(OUT_DIR, \"internships_synthetic.csv\"), index=False)\n",
    "print(f\"Synthetic students: {len(students)}  internships: {len(internships)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "663fb18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SBERT (all-mpnet-base-v2) and computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.35it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:18<00:00,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBF (SBERT) computed.\n",
      "Computing TF-IDF features...\n",
      "TF-IDF computed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 â€” CBF via SBERT and TF-IDF\n",
    "USE_TFIDF = True\n",
    "tfidf = None\n",
    "\n",
    "if USE_SBERT:\n",
    "    print(\"Loading SBERT (all-mpnet-base-v2) and computing embeddings...\")\n",
    "    sbert = SentenceTransformer('all-mpnet-base-v2')\n",
    "    internship_embs = sbert.encode(internships['job_text'].tolist(), show_progress_bar=True, convert_to_numpy=True)\n",
    "    student_embs = sbert.encode(students['profile_text'].tolist(), show_progress_bar=True, convert_to_numpy=True)\n",
    "    def normalize_rows(x):\n",
    "        norms = np.linalg.norm(x, axis=1, keepdims=True)\n",
    "        norms[norms==0] = 1.0\n",
    "        return x / norms\n",
    "    internship_embs = normalize_rows(internship_embs); student_embs = normalize_rows(student_embs)\n",
    "    cbf_sbert = cosine_similarity(student_embs, internship_embs)\n",
    "    print(\"CBF (SBERT) computed.\")\n",
    "else:\n",
    "    cbf_sbert = np.zeros((len(students), len(internships)))\n",
    "\n",
    "if USE_TFIDF:\n",
    "    print(\"Computing TF-IDF features...\")\n",
    "    tfidf = TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_features=8000)\n",
    "    job_tfidf = tfidf.fit_transform(internships['job_text'].tolist())\n",
    "    pr_tfidf = tfidf.transform(students['profile_text'].tolist())\n",
    "    cbf_tfidf = cosine_similarity(pr_tfidf, job_tfidf)\n",
    "    print(\"TF-IDF computed.\")\n",
    "else:\n",
    "    cbf_tfidf = np.zeros_like(cbf_sbert)\n",
    "\n",
    "CBF_SBERT_WEIGHT = 0.75 if USE_SBERT else 0.0\n",
    "CBF_TFIDF_WEIGHT = 1.0 - CBF_SBERT_WEIGHT\n",
    "cbf_ensemble = CBF_SBERT_WEIGHT * cbf_sbert + CBF_TFIDF_WEIGHT * cbf_tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03abcf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule matrix and eligibility mask built.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 â€” Rule-based scoring & eligibility\n",
    "def compute_rule_score_and_eligibility(srow, irow):\n",
    "    eligible = (srow['age'] >= irow['min_age']) and (srow['age'] <= irow['max_age'])\n",
    "    age_ok = 1.0 if eligible else 0.0\n",
    "    govt_bonus = 1.0 if (srow['govt_project'] and irow['org_pref_govt']) else 0.0\n",
    "    proj_imp = float(np.clip(srow['project_impact'], 0.0, 1.0))\n",
    "    freel_bonus = 0.5 if srow['freelancer'] else 0.0\n",
    "    fresher_bonus = 0.35 if srow['is_fresher'] else 0.0\n",
    "    stipend_min = internships['stipend'].min(); stipend_max = internships['stipend'].max()\n",
    "    stipend_score = (irow['stipend'] - stipend_min) / (stipend_max - stipend_min + 1e-9)\n",
    "    rule = 0.35*age_ok + 0.25*proj_imp + 0.15*freel_bonus + 0.1*fresher_bonus + 0.1*stipend_score + 0.05*govt_bonus\n",
    "    fairness_adj = 0.0\n",
    "    if srow.get('rural',0)==1:\n",
    "        fairness_adj += FAIRNESS_BOOST.get('rural', 0.0)\n",
    "    if srow.get('female',0)==1:\n",
    "        fairness_adj += FAIRNESS_BOOST.get('female', 0.0)\n",
    "    rule = min(1.0, rule + fairness_adj)\n",
    "    return float(rule), bool(eligible)\n",
    "\n",
    "rule_mat = np.zeros_like(cbf_ensemble)\n",
    "elig_mask = np.ones_like(cbf_ensemble, dtype=bool)\n",
    "for si, srow in students.iterrows():\n",
    "    for ji, irow in internships.iterrows():\n",
    "        rv, eligible = compute_rule_score_and_eligibility(srow, irow)\n",
    "        rule_mat[si, ji] = rv\n",
    "        elig_mask[si, ji] = eligible\n",
    "print(\"Rule matrix and eligibility mask built.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca90d0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated interactions: (9000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 â€” Simulate interactions for CF training\n",
    "interactions = []\n",
    "for si, srow in students.iterrows():\n",
    "    candidate_idxs = np.random.choice(len(internships), size=18, replace=False)\n",
    "    for j in candidate_idxs:\n",
    "        sim = float(cbf_ensemble[si, j])\n",
    "        rulev = float(rule_mat[si, j])\n",
    "        base = 4*sim + 3*rulev - 2.0\n",
    "        p = 1.0/(1.0 + math.exp(-base))\n",
    "        if not elig_mask[si,j]:\n",
    "            p *= 0.05\n",
    "        applied = (random.random() < p)\n",
    "        if applied:\n",
    "            rating = min(5, max(3, int(round(3 + 2*p + np.random.normal(0,0.25)))))\n",
    "        else:\n",
    "            rating = max(1, int(round(1 + 2*p + np.random.normal(0,0.4))))\n",
    "        interactions.append({'student_id': srow['student_id'], 'internship_id': internships.iloc[j]['internship_id'], 'rating': rating})\n",
    "inter_df = pd.DataFrame(interactions)\n",
    "print(\"Simulated interactions:\", inter_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57c7a688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running small Surprise SVD grid search (may take time)...\n",
      "Best SVD params: {'n_factors': 60, 'n_epochs': 30, 'lr_all': 0.01, 'reg_all': 0.05}\n",
      "SVD trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CF predictions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 1091.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CF matrix built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 â€” Collaborative Filtering (Surprise SVD)\n",
    "# NOTE: If surprise fails to install on Windows, either install the wheel manually OR use 'surprise-py' package\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "data = Dataset.load_from_df(inter_df[['student_id','internship_id','rating']], reader)\n",
    "\n",
    "# small grid search\n",
    "svd_param_grid = {'n_factors':[40,60], 'n_epochs':[20,30], 'lr_all':[0.005, 0.01], 'reg_all':[0.02, 0.05]}\n",
    "print(\"Running small Surprise SVD grid search (may take time)...\")\n",
    "sgs = SurpriseGridSearch(SVD, svd_param_grid, measures=['rmse'], cv=3, n_jobs=1)\n",
    "sgs.fit(data)\n",
    "best_svd_params = sgs.best_params['rmse']\n",
    "print(\"Best SVD params:\", best_svd_params)\n",
    "\n",
    "svd = SVD(**best_svd_params, random_state=SEED)\n",
    "trainset = data.build_full_trainset()\n",
    "svd.fit(trainset)\n",
    "print(\"SVD trained.\")\n",
    "\n",
    "student_ids = students['student_id'].tolist()\n",
    "intern_ids = internships['internship_id'].tolist()\n",
    "student_to_idx = {sid:i for i,sid in enumerate(student_ids)}\n",
    "intern_to_idx = {iid:i for i,iid in enumerate(intern_ids)}\n",
    "cf_mat = np.zeros((len(student_ids), len(intern_ids)))\n",
    "for s in tqdm(student_ids, desc=\"CF predictions\"):\n",
    "    for it in intern_ids:\n",
    "        cf_mat[student_to_idx[s], intern_to_idx[it]] = svd.predict(s, it).est\n",
    "print(\"CF matrix built.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "302222a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization and masking done.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7 â€” Normalize matrices and apply eligibility mask\n",
    "scaler = MinMaxScaler()\n",
    "cbf_norm = scaler.fit_transform(cbf_ensemble)\n",
    "cf_norm = scaler.fit_transform(cf_mat)\n",
    "rule_norm = MinMaxScaler().fit_transform(rule_mat)\n",
    "\n",
    "cbf_norm_mask = cbf_norm.copy(); cbf_norm_mask[~elig_mask] = 0.0\n",
    "cf_norm_mask = cf_norm.copy(); cf_norm_mask[~elig_mask] = 0.0\n",
    "rule_norm_mask = rule_norm.copy(); rule_norm_mask[~elig_mask] = 0.0\n",
    "\n",
    "print(\"Normalization and masking done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25229de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta training rows: 18000\n"
     ]
    }
   ],
   "source": [
    "# Cell 8 â€” Build feature rows and negative sampling\n",
    "def skill_overlap_ratio(s_skills, i_skills):\n",
    "    sset = set([x.strip().lower() for x in s_skills.split(',') if x.strip()])\n",
    "    iset = set([x.strip().lower() for x in i_skills.split(',') if x.strip()])\n",
    "    return len(sset & iset) / len(iset) if len(iset)>0 else 0.0\n",
    "\n",
    "feat_rows = []\n",
    "student_to_idx_local = student_to_idx; intern_to_idx_local = intern_to_idx\n",
    "\n",
    "for _, r in inter_df.iterrows():\n",
    "    sidx = student_to_idx_local[r['student_id']]; iidx = intern_to_idx_local[r['internship_id']]\n",
    "    srow = students.loc[sidx]; irow = internships.loc[iidx]\n",
    "    feat_rows.append({\n",
    "        'student_id': r['student_id'], 'internship_id': r['internship_id'],\n",
    "        'cbf': float(cbf_norm_mask[sidx,iidx]), 'cf': float(cf_norm_mask[sidx,iidx]), 'rule': float(rule_norm_mask[sidx,iidx]),\n",
    "        'skill_overlap': skill_overlap_ratio(srow['skills'], irow['required_skills']),\n",
    "        'domain_match': 1.0 if srow['domain']==irow['domain'] else 0.0,\n",
    "        'age_gap': float(abs(srow['age'] - (irow['min_age'] + irow['max_age'])/2.0))/20.0,\n",
    "        'stipend_norm': (irow['stipend'] - internships['stipend'].min())/(internships['stipend'].max()-internships['stipend'].min()+1e-9),\n",
    "        'remote_match': 1.0 if irow['remote']==1 else 0.0,\n",
    "        'github_flag': 1.0 if srow['github'] else 0.0,\n",
    "        'project_impact': srow['project_impact'], 'rural': srow['rural'], 'female': srow['female'],\n",
    "        'rating': r['rating']\n",
    "    })\n",
    "\n",
    "# negative sampling to balance\n",
    "n_neg = len(feat_rows)\n",
    "existing_pairs = set(zip(inter_df['student_id'], inter_df['internship_id']))\n",
    "neg_samples=[]\n",
    "while len(neg_samples) < n_neg:\n",
    "    s = random.choice(student_ids); i = random.choice(intern_ids)\n",
    "    if (s,i) in existing_pairs: continue\n",
    "    sidx = student_to_idx_local[s]; iidx = intern_to_idx_local[i]\n",
    "    if not elig_mask[sidx,iidx]: continue\n",
    "    neg_samples.append((s,i))\n",
    "for s,i in neg_samples:\n",
    "    sidx = student_to_idx_local[s]; iidx = intern_to_idx_local[i]\n",
    "    srow = students.loc[sidx]; irow = internships.loc[iidx]\n",
    "    feat_rows.append({\n",
    "        'student_id': s, 'internship_id': i,\n",
    "        'cbf': float(cbf_norm_mask[sidx,iidx]), 'cf': float(cf_norm_mask[sidx,iidx]), 'rule': float(rule_norm_mask[sidx,iidx]),\n",
    "        'skill_overlap': skill_overlap_ratio(srow['skills'], irow['required_skills']),\n",
    "        'domain_match': 1.0 if srow['domain']==irow['domain'] else 0.0,\n",
    "        'age_gap': float(abs(srow['age'] - (irow['min_age'] + irow['max_age'])/2.0))/20.0,\n",
    "        'stipend_norm': (irow['stipend'] - internships['stipend'].min())/(internships['stipend'].max()-internships['stipend'].min()+1e-9),\n",
    "        'remote_match': 0.0, 'github_flag': 1.0 if srow['github'] else 0.0,\n",
    "        'project_impact': srow['project_impact'], 'rural': srow['rural'], 'female': srow['female'],\n",
    "        'rating': 1\n",
    "    })\n",
    "\n",
    "meta_df = pd.DataFrame(feat_rows).reset_index(drop=True)\n",
    "print(\"Meta training rows:\", len(meta_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36e06c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta model R2 (train): 0.5664399862289429\n",
      "Top feature importances: {'remote_match': 0.47814059257507324, 'cf': 0.22124063968658447, 'cbf': 0.05108686164021492, 'rule': 0.050083015114068985, 'age_gap': 0.03980773687362671, 'project_impact': 0.030055508017539978, 'rural': 0.02842850424349308, 'female': 0.023790685459971428, 'stipend_norm': 0.02167050540447235, 'skill_overlap': 0.02166503667831421}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['outputs_recommender_v2\\\\meta_scaler.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 9 â€” Train XGBoost meta model with K-Fold + early stopping\n",
    "feature_cols = ['cbf','cf','rule','skill_overlap','domain_match','age_gap','stipend_norm','remote_match','github_flag','project_impact','rural','female']\n",
    "X = meta_df[feature_cols].copy()\n",
    "y = meta_df['rating'].copy()\n",
    "\n",
    "scaler_std = StandardScaler()\n",
    "X[['age_gap','project_impact','skill_overlap','stipend_norm']] = scaler_std.fit_transform(X[['age_gap','project_impact','skill_overlap','stipend_norm']])\n",
    "\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "meta = XGBRegressor(n_estimators=1000, learning_rate=0.03, max_depth=6, subsample=0.85, colsample_bytree=0.8, random_state=SEED, verbosity=0)\n",
    "\n",
    "best_rounds = []\n",
    "for train_idx, val_idx in kf.split(X):\n",
    "    Xtr, Xval = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    ytr, yval = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    try:\n",
    "        meta.fit(Xtr, ytr, eval_set=[(Xval,yval)], early_stopping_rounds=30, verbose=False)\n",
    "    except TypeError:\n",
    "        from xgboost.callback import EarlyStopping\n",
    "        meta.fit(Xtr, ytr, eval_set=[(Xval,yval)], callbacks=[EarlyStopping(rounds=30)], verbose=False)\n",
    "    try:\n",
    "        best_rounds.append(meta.best_iteration + 1)\n",
    "    except Exception:\n",
    "        best_rounds.append(100)\n",
    "\n",
    "n_rounds = int(np.median(best_rounds))\n",
    "meta = XGBRegressor(n_estimators=max(50, n_rounds), learning_rate=0.03, max_depth=6, subsample=0.85, colsample_bytree=0.8, random_state=SEED, verbosity=0)\n",
    "try:\n",
    "    meta.fit(X, y, eval_set=[(X, y)], early_stopping_rounds=30, verbose=False)\n",
    "except TypeError:\n",
    "    from xgboost.callback import EarlyStopping\n",
    "    meta.fit(X, y, eval_set=[(X, y)], callbacks=[EarlyStopping(rounds=30)], verbose=False)\n",
    "\n",
    "# Evaluate & save\n",
    "y_pred = meta.predict(X)\n",
    "r2 = r2_score(y, y_pred)\n",
    "fi_series = pd.Series(meta.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
    "fi = fi_series.round(4).to_dict()\n",
    "print(\"Meta model R2 (train):\", r2)\n",
    "print(\"Top feature importances:\", fi_series.head(10).to_dict())\n",
    "\n",
    "joblib.dump(meta, os.path.join(OUT_DIR, \"meta_model_xgb.pkl\"))\n",
    "joblib.dump(scaler_std, os.path.join(OUT_DIR, \"meta_scaler.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a752e4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated mean NDCG@10: 0.9141251437442538 MAP@10: 0.9455015773284622\n"
     ]
    }
   ],
   "source": [
    "# Cell 10 â€” Ranking estimation utilities & run\n",
    "def map_at_k(true_labels, pred_scores, k=10):\n",
    "    order = np.argsort(pred_scores)[::-1][:k]\n",
    "    rel = np.array(true_labels)[order] > 3\n",
    "    if rel.sum() == 0: return 0.0\n",
    "    precisions = [(rel[:i+1].sum()/(i+1)) for i in range(len(rel)) if rel[i]]\n",
    "    return np.mean(precisions) if precisions else 0.0\n",
    "\n",
    "def ndcg_at_k(true, pred, k=10):\n",
    "    try:\n",
    "        return ndcg_score([true],[pred], k=k)\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "def ranking_estimate(meta_df, model, sample_students=100, k=10):\n",
    "    sids = meta_df['student_id'].unique()\n",
    "    if len(sids)==0: return {\"ndcg\":0.0,\"map\":0.0}\n",
    "    sel = np.random.choice(sids, size=min(sample_students,len(sids)), replace=False)\n",
    "    ndcg_list=[]; map_list=[]\n",
    "    for s in sel:\n",
    "        subset = meta_df[meta_df['student_id']==s]\n",
    "        if subset.shape[0] < 5: continue\n",
    "        Xloc = subset[feature_cols].copy()\n",
    "        Xloc[['age_gap','project_impact','skill_overlap','stipend_norm']] = scaler_std.transform(Xloc[['age_gap','project_impact','skill_overlap','stipend_norm']])\n",
    "        preds = model.predict(Xloc)\n",
    "        true = subset['rating'].values\n",
    "        ndcg_list.append(ndcg_at_k(true, preds, k))\n",
    "        map_list.append(map_at_k(true, preds, k))\n",
    "    return {\"ndcg\": np.mean(ndcg_list) if ndcg_list else 0.0, \"map\": np.mean(map_list) if map_list else 0.0}\n",
    "\n",
    "metrics = ranking_estimate(meta_df, meta, sample_students=120, k=10)\n",
    "print(\"Estimated mean NDCG@10:\", metrics['ndcg'], \"MAP@10:\", metrics['map'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20fc1839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved recommendations -> outputs_recommender_v2\\recommendations.csv (rows=5000)\n"
     ]
    }
   ],
   "source": [
    "# Cell 11 â€” Build features for all pairs, predict, and top-K per student\n",
    "S = len(students); I = len(internships)\n",
    "all_features = np.zeros((S * I, len(feature_cols)), dtype=float)\n",
    "idx = 0\n",
    "for s in range(S):\n",
    "    srow = students.loc[s]\n",
    "    for i in range(I):\n",
    "        if not elig_mask[s,i]:\n",
    "            all_features[idx, :] = np.zeros(len(feature_cols)); idx += 1; continue\n",
    "        irow = internships.loc[i]\n",
    "        fv = [\n",
    "            float(cbf_norm_mask[s,i]), float(cf_norm_mask[s,i]), float(rule_norm_mask[s,i]),\n",
    "            skill_overlap_ratio(srow['skills'], irow['required_skills']),\n",
    "            1.0 if srow['domain']==irow['domain'] else 0.0,\n",
    "            float(abs(srow['age'] - (irow['min_age'] + irow['max_age'])/2.0))/20.0,\n",
    "            (irow['stipend'] - internships['stipend'].min())/(internships['stipend'].max()-internships['stipend'].min()+1e-9),\n",
    "            1.0 if irow['remote']==1 else 0.0,\n",
    "            1.0 if srow['github'] else 0.0,\n",
    "            srow['project_impact'], srow['rural'], srow['female']\n",
    "        ]\n",
    "        all_features[idx, :] = fv\n",
    "        idx += 1\n",
    "\n",
    "all_features_df = pd.DataFrame(all_features, columns=feature_cols)\n",
    "all_features_df[['age_gap','project_impact','skill_overlap','stipend_norm']] = scaler_std.transform(all_features_df[['age_gap','project_impact','skill_overlap','stipend_norm']])\n",
    "\n",
    "try:\n",
    "    preds_flat = meta.predict(all_features_df)\n",
    "except Exception:\n",
    "    preds_flat = all_features_df[['cbf','cf','rule']].dot(np.array([BASE_ALPHA, BASE_BETA, BASE_GAMMA]))\n",
    "preds_flat = np.array(preds_flat).reshape(S, I)\n",
    "meta_preds = preds_flat\n",
    "meta_norm = (meta_preds - meta_preds.min())/(meta_preds.max()-meta_preds.min()+1e-9)\n",
    "\n",
    "# produce top-K recs\n",
    "recs = []\n",
    "for s in range(S):\n",
    "    scores = meta_norm[s]\n",
    "    scores = np.where(elig_mask[s], scores, -1.0)\n",
    "    top_idx = np.argsort(scores)[::-1][:TOP_K]\n",
    "    for rank, i in enumerate(top_idx, start=1):\n",
    "        recs.append({\n",
    "            'student_idx': s, 'student_id': students.loc[s,'student_id'],\n",
    "            'intern_idx': int(i), 'internship_id': internships.loc[i,'internship_id'],\n",
    "            'title': internships.loc[i,'title'], 'domain': internships.loc[i,'domain'],\n",
    "            'score': float(scores[i]), 'rank': rank\n",
    "        })\n",
    "recs_df = pd.DataFrame(recs)\n",
    "recs_csv = os.path.join(OUT_DIR, \"recommendations.csv\")\n",
    "recs_df.to_csv(recs_csv, index=False)\n",
    "print(f\"Saved recommendations -> {recs_csv} (rows={len(recs_df)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1521a5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved allocations -> outputs_recommender_v2\\allocations.csv (rows=423)\n"
     ]
    }
   ],
   "source": [
    "# Cell 12 â€” Allocation with OR-Tools (capacities + reserved seats)\n",
    "def allocate_with_constraints(score_matrix, capacity_array, eligibility_mask, students_df, internships_df, global_reserved_pct=0.0):\n",
    "    S, I = score_matrix.shape\n",
    "    solver = pywraplp.Solver.CreateSolver('CBC')\n",
    "    if not solver:\n",
    "        raise RuntimeError(\"OR-Tools solver not available.\")\n",
    "    x={}\n",
    "    for s in range(S):\n",
    "        for i in range(I):\n",
    "            if eligibility_mask[s,i]:\n",
    "                x[(s,i)] = solver.IntVar(0,1,f\"x_{s}_{i}\")\n",
    "    for s in range(S):\n",
    "        solver.Add(solver.Sum([x[(s,i)] for i in range(I) if (s,i) in x]) <= 1)\n",
    "    for i in range(I):\n",
    "        solver.Add(solver.Sum([x[(s,i)] for s in range(S) if (s,i) in x]) <= int(capacity_array[i]))\n",
    "    reserved_count = int(np.floor(global_reserved_pct * capacity_array.sum()))\n",
    "    if reserved_count > 0:\n",
    "        priority_vars=[]\n",
    "        for s in range(S):\n",
    "            if students_df.loc[s,'govt_project']==1:\n",
    "                for i in range(I):\n",
    "                    if (s,i) in x:\n",
    "                        priority_vars.append(x[(s,i)])\n",
    "        if priority_vars:\n",
    "            solver.Add(solver.Sum(priority_vars) >= min(reserved_count, len(priority_vars)))\n",
    "    obj = solver.Objective()\n",
    "    for (s,i), var in x.items():\n",
    "        obj.SetCoefficient(var, float(score_matrix[s,i]))\n",
    "    obj.SetMaximization()\n",
    "    status = solver.Solve()\n",
    "    if status not in (pywraplp.Solver.OPTIMAL, pywraplp.Solver.FEASIBLE):\n",
    "        print(\"No feasible allocation found.\")\n",
    "        return pd.DataFrame()\n",
    "    assignments=[]\n",
    "    for (s,i), var in x.items():\n",
    "        if var.solution_value() > 0.5:\n",
    "            assignments.append({'student_idx': s, 'intern_idx': i, 'student_id': students_df.loc[s,'student_id'], 'internship_id': internships_df.loc[i,'internship_id'], 'score': float(score_matrix[s,i])})\n",
    "    return pd.DataFrame(assignments).sort_values('score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "assignments_df = allocate_with_constraints(meta_norm, internships['capacity'].values, elig_mask, students, internships, global_reserved_pct=GLOBAL_RESERVED_PERCENT)\n",
    "alloc_csv = os.path.join(OUT_DIR, \"allocations.csv\")\n",
    "assignments_df.to_csv(alloc_csv, index=False)\n",
    "print(f\"Saved allocations -> {alloc_csv} (rows={len(assignments_df)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2892b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved models & artifacts into outputs_recommender_v2/\n",
      "\n",
      "=== PIPELINE SUMMARY ===\n",
      "Meta model R2 (train): 0.5664399862289429\n",
      "Estimated mean NDCG@10 (sample): 0.9141251437442538\n",
      "Estimated mean MAP@10 (sample): 0.9455015773284622\n",
      "Outputs saved to: outputs_recommender_v2\n",
      "recommendations.csv rows: 5000\n",
      "allocations.csv rows: 423\n",
      "evaluation_metrics.csv saved: outputs_recommender_v2\\evaluation_metrics.csv\n",
      "feature_importances.csv saved: outputs_recommender_v2\\feature_importances.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 13 â€” Save artifacts and summary\n",
    "metrics_summary = {\n",
    "    \"meta_r2_train\": float(r2),\n",
    "    \"ndcg_at_10_sample\": float(metrics['ndcg']),\n",
    "    \"map_at_10_sample\": float(metrics['map']),\n",
    "    \"num_students\": int(len(students)),\n",
    "    \"num_internships\": int(len(internships)),\n",
    "    \"num_interactions\": int(len(inter_df)),\n",
    "    \"num_recommendation_rows\": int(len(recs_df)),\n",
    "    \"num_assignments\": int(len(assignments_df))\n",
    "}\n",
    "metrics_df = pd.DataFrame([metrics_summary])\n",
    "metrics_csv = os.path.join(OUT_DIR, \"evaluation_metrics.csv\")\n",
    "metrics_df.to_csv(metrics_csv, index=False)\n",
    "fi_df = pd.DataFrame(list(fi.items()), columns=[\"feature\",\"importance\"]).sort_values(\"importance\", ascending=False)\n",
    "fi_csv = os.path.join(OUT_DIR, \"feature_importances.csv\")\n",
    "fi_df.to_csv(fi_csv, index=False)\n",
    "\n",
    "joblib.dump(meta, os.path.join(OUT_DIR, \"meta_model_xgb.pkl\"))\n",
    "joblib.dump(svd, os.path.join(OUT_DIR, \"svd_model.pkl\"))\n",
    "if USE_SBERT:\n",
    "    sbert.save(os.path.join(OUT_DIR, \"sbert_all_mpnet_model\"))\n",
    "print(f\"Saved models & artifacts into {OUT_DIR}/\")\n",
    "\n",
    "print(\"\\n=== PIPELINE SUMMARY ===\")\n",
    "print(\"Meta model R2 (train):\", r2)\n",
    "print(\"Estimated mean NDCG@10 (sample):\", metrics['ndcg'])\n",
    "print(\"Estimated mean MAP@10 (sample):\", metrics['map'])\n",
    "print(\"Outputs saved to:\", OUT_DIR)\n",
    "print(\"recommendations.csv rows:\", len(recs_df))\n",
    "print(\"allocations.csv rows:\", len(assignments_df))\n",
    "print(\"evaluation_metrics.csv saved:\", metrics_csv)\n",
    "print(\"feature_importances.csv saved:\", fi_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fabe35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
